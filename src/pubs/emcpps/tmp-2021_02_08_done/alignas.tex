% 8 Feb 2021 JMB, file comment cleanup

\emcppsFeature{
    short={\lstinline!alignas!},
    tocshort={\TOCCode alignas},
    long={The {\SecCode alignas} Decorator},
    toclong={The \lstinline!alignas! Decorator},
    rhshort={\RHCode alignas},
}{alignas}
%\section[{\tt alignas}]{The {\SecCode alignas} Decorator\sectionmark{\RHCode alignas}}\label{alignas}\sectionmark{\RHCode alignas}
\setcounter{table}{0}
\setcounter{footnote}{0}
\setcounter{lstlisting}{0}

\texttt{alignas}, a keyword that acts like an attribute, is used to widen (make more strict)
the \textbf{alignment} of a \textbf{variable}, \textbf{user-defined
type}, or \textbf{data member}.

\subsection[Description]{Description}\label{description}

The \texttt{alignas} specifier provides a means of further restricting
the granularity at which (1) a particular object of arbitrary type, (2)
a user-defined type (\texttt{class}, \texttt{struct}, \texttt{union}, or
\texttt{enum}), or (3) an individual data member is permitted to reside
within the virtual-memory-address space.

\subsubsection[Restricting the alignment of a particular object]{Restricting the alignment of a particular object}\label{restricting-the-alignment-of-a-particular-object}

In its most basic form, \texttt{alignas} acts like an
attribute that accepts (as an argument) an
\textbf{integral constant expression} representing an explicitly
supplied minimum alignment value:

\begin{lstlisting}[language=C++]
alignas(64) int i;    // OK, (ù{\codeincomments{i}}ù) is aligned on a 64-byte address boundary.
int j alignas(8), k;  // OK, (ù{\codeincomments{j}}ù) is 8-byte aligned; (ù{\codeincomments{k}}ù) remains naturally aligned.
\end{lstlisting}

\noindent If more than one alignment pertains to a given object, the most
restrictive alignment value is applied:

\begin{lstlisting}[language=C++]
alignas(4) alignas(8) alignas(2) char m;  // OK, (ù{\codeincomments{m}}ù) is 8-byte aligned.
alignas(8) int n alignas(16);             // OK, (ù{\codeincomments{n}}ù) is 16-byte aligned.
\end{lstlisting}

\noindent For a program to be \textbf{well formed}, a specified alignment value
must satisfy several\linebreak[4] \mbox{requirements}:

\begin{enumerate}
\item{Be either zero or a non-negative integral power of two of type \texttt{std::size\_t} (0, 1, 2, 4, 8, 16\dots).}
\item{Be at least the minimum alignment\cprotect\footnote{The minimum alignment of an entity is the least restrictive memory-address boundary at which the entity can be placed and have the program continue to work properly. This value is platform dependent and often subject to compiler controls but, by default, is often well approximated by \textbf{natural alignment}; see \textit{\titleref{alignas-appendix}: \titleref{natural-alignment}} on page \pageref{natural-alignment}.} required by the decorated entity.}
\item{Be no more than the largest alignment\cprotect\footnote{The notion of the largest supported alignment is characterized by both \textbf{maximal alignment} and the maximum \textbf{extended alignment}. \textbf{Maximal alignment} is defined as that most restrictive alignment that is valid in \emph{all} contexts on the current platform. All fundamental and pointer types necessarily have a minimal alignment that is less than or equal to \texttt{alignof(std::max\_align\_t)} — typically 8 or 16. Any alignment value greater than \textbf{maximal alignment} is an \textbf{extended alignment} value. Whether any extended alignment is supported (and in which contexts) is implementation defined. On typical platforms, extended alignment will often be as large as $2^{18}$ or $2^{19}$, however implementations may warn when the alignment of a global object exceeds some maximal hardware threshold (such as the size of a physical memory page, e.g., 4096 or 8192). For \textbf{automatic variables} (defined on the program stack), making alignment more restrictive than what would naturally be employed  is seldom desired because at most one thread is able to access proximately located variables there unless explicitly passed in via address to separate threads; see \textit{\titleref{alignas-use-cases}: \titleref{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}} on page~\pageref{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}. Note that, in the case of \texttt{i} in the first code snippet on page~\pageref{restricting-the-alignment-of-a-particular-object}, a conforming platform that did not support an extended alignment of 64 would be required to report an error at compile time.} supported on the platform in the context in which the entity appears.}
\end{enumerate}

\noindent Additionally, if the specified alignment value is zero, the
\texttt{alignas} specifier is ignored:

\begin{lstlisting}[language=C++]
// Static variables declared at namespace scope
alignas(32) int i0;  // OK, aligned on a 32-byte boundary (extended alignment)
alignas(16) int i1;  // OK, aligned on a 16-byte boundary (maximum alignment)
alignas(8)  int i2;  // OK, aligned on an 8-byte boundary
alignas(7)  int i3;  // error: not a power of two
alignas(4)  int i4;  // OK, no change to alignment boundary
alignas(2)  int i5;  // error: less than minimum alignment on this platform
alignas(0)  int i6;  // OK, (ù{\codeincomments{alignas}}ù) specifier ignored

alignas(1024 * 16) int i7;
    // OK, might warn: e.g., exceeds (physical) page size on current platform

alignas(1024 * 1024 * 512) int i8;
    // (likely) compile-time error: e.g., exceeds maximum size of object file

alignas(8) char buf[128];  // create 8-byte-aligned, 128-byte character buffer

void f()
{
    // automatic variables declared at function scope
    alignas(4)  double e0;  // error: less than minimum alignment on this platform
    alignas(8)  double e1;  // OK, no-change to (8-byte) alignment boundary
    alignas(16) double e2;  // OK, aligned to maximum (fundamental) alignment value
    alignas(32) double e3;  // OK, maximum alignment value exceeded; might warn
}
\end{lstlisting}

\subsubsection[Restricting the alignment of a user-defined type]{Restricting the alignment of a user-defined type}\label{restricting-the-alignment-of-a-user-defined-type}

The \texttt{alignas} specifier can also be used to specify alignment for
user-defined types (UDTs), such as a \texttt{class}, \texttt{struct},
\texttt{union}, or \texttt{enum}. When specifying the alignment of a UDT,
 the \texttt{alignas} keyword is placed \emph{after} the
type specifier (e.g., \texttt{class}) and just before the name of the
type (e.g., \texttt{C}):

\begin{lstlisting}[language=C++]
class alignas(2)  C { };  // OK, aligned on a 2-byte boundary; size = 2
struct alignas(4) S { };  // OK, aligned on a 4-byte boundary; size = 4
union alignas(8)  U { };  // OK, aligned on an 8-byte boundary; size = 8
enum alignas(16)  E { };  // OK, aligned on a 16-byte boundary; size = 4
\end{lstlisting}

\noindent Notice that, for each of \texttt{class}, \texttt{struct}, and
\texttt{union} above, the \texttt{sizeof} objects of that type increased
to match the alignment; in the case of the \texttt{enum}, however, the
size remains that of the default \textbf{underlying type} (e.g., 4
bytes) on the current platform.{\cprotect\footnote{When \texttt{alignas}
is applied to an enumeration \texttt{E}, the Standard does not
indicate whether padding bits are added to \texttt{E}'s object
representation or not, affecting the result of \texttt{sizeof(E)}. The
implementation variance resulting from this lack of clarity in the
  Standard was captured in \textbf{miller17}. The outcome of the core
  issue was to completely remove permission for \texttt{alignas} to be
  applied to enumerations (see \textbf{iso18a}). Therefore, conforming implementations will
  eventually stop accepting the \texttt{alignas} specifier on
  enumerations in the future.}}

Again, specifying an alignment that is less than what would occur
naturally or else is restricted explicitly is ill formed:

\begin{lstlisting}[language=C++]
struct alignas(2) T0 { int i; };
    // Error: Alignment of (ù{\codeincomments{T0}}ù) (2) is less than that of (ù{\codeincomments{int}}ù) (4).
struct alignas(1) T1 { C c; };
    // Error: Alignment of (ù{\codeincomments{T1}}ù) (1) is less than that of (ù{\codeincomments{C}}ù) (2).
\end{lstlisting}


\subsubsection[Restricting the alignment of individual data members]{Restricting the alignment of individual data members}\label{restricting-the-alignment-of-individual-data-members}

Within a user-defined type (\texttt{class}, \texttt{struct}, or
\texttt{union}), using the attribute-like syntax of the
\texttt{alignas} keyword to specify the alignments of individual data
members is possible:

\begin{lstlisting}[language=C++]
struct T2
{
    alignas(8)  char   x;  // size   1; alignment 8
    alignas(16) int    y;  // size   4; alignment 16
    alignas(64) double y;  // size   8; alignment 64
};  // size 128; alignment 64
\end{lstlisting}

\noindent The effect here is the same as if we had added the padding explicitly
and then set the alignment of the structure overall:

\begin{lstlisting}[language=C++]
struct alignas(64) T3
{
    char   x;      // size   1; alignment 8
    char   a[15];  // padding
    int    y;      // size   4; alignment 16
    char   b[44];  // padding
    double z;      // size   8; alignment 64
    char   c[56];  // padding (optional)
};  // size 128; alignment 64
\end{lstlisting}

\noindent Again, if more than one attribute pertains to a given data member,
the maximum applicable alignment value is applied:

\begin{lstlisting}[language=C++]
struct T4
{
    alignas(2) char
        c1 alignas(1),  // size 1; alignment 2
        c2 alignas(2),  // size 1; alignment 2
        c4 alignas(4);  // size 1; alignment 4
};                      // size 8; alignment 4
\end{lstlisting}


\subsubsection[Matching the alignment of another type]{Matching the alignment of another type}\label{matching-the-alignment-of-another-type}

The \texttt{alignas} specifier also accepts (as an argument) a type
identifier. In its alternate form, \texttt{alignas(T)} is strictly
equivalent to \texttt{alignas(alignof(T))}:

\begin{lstlisting}[language=C++]
alignas(int) char c;  // equivalent to (ù{\codeincomments{alignas(alignof(int)) char c;}}ù)
\end{lstlisting}


\subsection[Use Cases]{Use Cases}\label{alignas-use-cases}

\subsubsection[Creating a sufficiently aligned object buffer]{Creating a sufficiently aligned object buffer}\label{creating-a-sufficiently-aligned-object-buffer}

When writing low-level, system-infrastructure code, constructing an object within a raw buffer is sometimes useful. As a minimal
example, consider a function that uses a local character buffer to
create an object of type \texttt{std::complex<long}~\texttt{double>} on
the program stack using placement \texttt{new}:

\begin{lstlisting}[language=C++]
void f()
{
    // ...
    char objectBuffer[sizeof(std::complex<long double>)];  // BAD IDEA
    // ...
    new(objectBuffer) std::complex<long double>(1.0, 0.0);  // Might dump core!
    // ...
}
\end{lstlisting}

\noindent The essential problem with the code above is that \texttt{objectBuffer},
being an array of characters (each having an alignment of 1), is itself
byte aligned. The compiler is therefore free to place it on any address
boundary. On the other hand, \texttt{std::complex<long}~\texttt{double>} is an aggregate consisting of two \texttt{long}~\texttt{double} objects
and therefore necessarily requires (at least) the same strict alignment
(typically 16) as the two \texttt{long}~\texttt{double} objects it comprises. Previous
solutions to this problem involved creating a \texttt{union} of the
object buffer and some maximally aligned type (e.g.,
\texttt{std::max\_align\_t}):

\begin{lstlisting}[language=C++]
#include <cstddef>  // (ù{\codeincomments{std::max\_align\_t}}ù)

void f()
{
    // ...

    union {                                              // awkward workaround
        std::max_align_t dummy;  // (ù{\codeincomments{typedef}}ù) to maximally aligned type
        char objectBuffer[sizeof(std::complex<long double>)];
    } objectBuffer;

    // ...

    new(&objectBuffer) std::complex<long double>(1.0, 0.0);  // OK

    // ...
}
\end{lstlisting}

\noindent Using the alternate syntax for \texttt{alignas}, we can avoid gratuitous
complexity and just state our intentions explicitly:

\begin{lstlisting}[language=C++]
void f()
{
    // ...

    alignas(std::complex<long double>) char objectBuffer[
                              sizeof(std::complex<long double>)];  // GOOD IDEA

    // ...

    new(objectBuffer) std::complex<long double>(1.0, 0.0);  // OK

    // ...
}
\end{lstlisting}


\subsubsection[Ensuring proper alignment for architecture-specific instructions]{Ensuring proper alignment for architecture-specific instructions}\label{ensuring-proper-alignment-for-architecture-specific-instructions}

Architecture-specific instructions or compiler intrinsics might require
the data they act on to have a specific alignment. One example of such
intrinsics is the \emph{Streaming SIMD Extensions (SSE)}\footnote{\textbf{inteliig}, ``Technologies: SSE"} instruction set available on the x86
architecture. SSE instructions operate on groups of four 32-bit
single-precision floating-point numbers at a time, which are required to
be 16-byte aligned.{\cprotect\footnote{``Data must be
16-byte aligned when loading to and storing from the 128-bit XMM
  registers used by SSE/SSE2/SSE3/SSSE3'': see \textbf{{intel16}},
  section 4.4.4, ``Data Alignment for 128-Bit Data," pp. 4-19--4-20.}} The
\texttt{alignas} specifier can be used to create a type satisfying this requirement:

\begin{lstlisting}[language=C++]
struct SSEVector
{
    alignas(16) float d_data[4];
};
\end{lstlisting}

\noindent Each object of the \texttt{SSEVector} type above is guaranteed always to
be aligned to a 16-byte boundary and can therefore be safely (and
conveniently) used with SSE intrinsics:

\begin{lstlisting}[language=C++]
#include <xmmintrin.h>  // (ù{\codeincomments{\_\_m128}}ù) and (ù{\codeincomments{\_mm\_XXX}}ù) functions

void f()
{
    const SSEVector v0 = {0.0f, 1.0f, 2.0f, 3.0f};
    const SSEVector v1 = {10.0f, 10.0f, 10.0f, 10.0f};

    __m128 sseV0 = _mm_load_ps(v0.d_data);
    __m128 sseV1 = _mm_load_ps(v1.d_data);
        // (ù{\codeincomments{\_mm\_load\_ps}}ù) requires the given (ù{\codeincomments{float}}ù) array to be 16-byte aligned.
        // The data is loaded into a dedicated 128-bit CPU register.

    __m128 sseResult = _mm_add_ps(sseV0, sseV1);
        // sum two 128-bit registers; typically generates an (ù{\codeincomments{addps}}ù) instruction

    SSEVector vResult;
    _mm_store_ps(vResult.d_data, sseResult);
        // Store the result of the sum back into a (ù{\codeincomments{float}}ù) array.

    assert(vResult.d_data[0] == 10.0f);
    assert(vResult.d_data[1] == 11.0f);
    assert(vResult.d_data[2] == 12.0f);
    assert(vResult.d_data[3] == 13.0f);
}
\end{lstlisting}


\subsubsection[Avoiding \textbf{false sharing} among distinct objects in a multi-threaded program]{Avoiding \textbf{false sharing} among distinct objects in a multi-threaded program}\label{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}

In the context of an application where multithreading has been employed
to improve performance, seeing
a previously single-threaded workflow become even less performant after
a parallelization attempt can be surprising (and disheartening). One possible insidious cause of such
disappointing results comes from \textbf{false sharing} --- a situation
in which multiple threads unwittingly harm each other's performance
while writing to logically independent variables that happen to reside
on the same \textbf{cache line}; see {\it \titleref{alignas-appendix}:} {\it\titleref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}} on page~\pageref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}.

As a simple (purely pedagogical) illustration of the potential
performance degradation resulting from \textbf{false sharing}, consider
a function that spawns separate threads to repeatedly increment
(concurrently) logically distinct variables that happen to reside in
close proximity on the program stack:

\begin{lstlisting}[language=C++]
#include <thread>  // (ù{\codeincomments{std::thread}}ù)

volatile int target = 0;  // updated asynchronously from multiple threads

void incrementJob(int* p);
    // Repeatedly increment (ù{\codeincomments{*p}}ù) a large, fixed number of times;
    // periodically write its current value to (ù{\codeincomments{target}}ù).

void f()
{
    int i0 = 0;  // Here, (ù{\codeincomments{i0}}ù) and (ù{\codeincomments{i1}}ù) likely share the same cache line,
    int i1 = 0;  // i.e., byte-aligned memory block on the program stack.

    std::thread t0(&incrementJob, &i0);
    std::thread t1(&incrementJob, &i1);
        // Spawn two parallel jobs incrementing the respective variables.

    t0.join();
    t1.join();
        // Wait for both jobs to be completed.
}
\end{lstlisting}

\noindent In the simplistic example above, the proximity in memory between
\texttt{i0} and \texttt{i1} can result in their belonging to the same
\textbf{cache line}, thus leading to \textbf{false sharing}. By
prepending \texttt{alignas(64)} to the declaration of both integers, we
ensure that the two variables reside on distinct cache lines:

\begin{lstlisting}[language=C++]
// ...

void f()
{
    alignas(64) int i0 = 0;   // Assuming a cache line on this platform is 64
    alignas(64) int i1 = 0;   // bytes, (ù{\codeincomments{i0}}ù) and (ù{\codeincomments{i1}}ù) will be on separate ones.

    // ...
\end{lstlisting}

\noindent As an empirical demonstration of the effects of \textbf{false sharing},
a benchmark program repeatedly calling \texttt{f} completed its
execution seven times faster on average when compared to the same
program without use of \texttt{alignas}.{\cprotect\footnote{The benchmark
program was compiled using Clang 11.0.0 using \texttt{-Ofast},
\texttt{-march=native}, and \mbox{\texttt{-std=c++11}}. The program was then
executed on a machine running Windows 10 x64, equipped with an Intel
Core i7-9700k CPU (8 cores, 64-byte cache line size). Over the
course of multiple runs, the version of the benchmark without
\texttt{alignas} took 18.5967ms to complete (on average), while the
version with \texttt{alignas} took 2.45333ms to complete (on average).
  See \textbf{{[PRODUCTION: CODE PROVIDED WITH BOOK] alignasbenchmark}} for the source code of the program.}}

\subsubsection[Avoiding \textbf{false sharing} within a single thread-aware object]{Avoiding \textbf{false sharing} within a single thread-aware object}\label{avoiding-false-sharing-within-a-single-thread-aware-object}

A real-world scenario where the need for preventing \textbf{false
sharing} is fundamental occurs in the implementation of high-performance
concurrent data structures. As an example, a thread-safe ring buffer
might make use of \texttt{alignas} to ensure that the indices of the
head and tail of the buffer are aligned at the start of a cache line
(typically 64, 128, or 256 bytes), thereby preventing them from
occupying the same one.

\begin{lstlisting}[language=C++]
class ThreadSafeRingBuffer
{
    alignas(cpuCacheSize) std::atomic<std::size_t> d_head;
    alignas(cpuCacheSize) std::atomic<std::size_t> d_tail;

    // ...
};
\end{lstlisting}

\noindent Not aligning \texttt{d\_head} and \texttt{d\_tail} (above) to the CPU
cache size might result in poor performance of the
\texttt{ThreadSafeRingBuffer} because CPU cores that need to access only one
of the variables will inadvertently load the other one as well,
triggering expensive hardware-level coherency mechanisms between the
cores' caches. On the other hand, specifying such substantially stricter
alignment on consecutive data members necessarily increases the size of
the object; see {\it\titleref{potential-pitfalls}:} {\it\titleref{stricter-alignment-might-reduce-cache-utilization}} on page~\pageref{stricter-alignment-might-reduce-cache-utilization}.

\subsection[Potential Pitfalls]{Potential Pitfalls}\label{potential-pitfalls}

\subsubsection[Underspecifying alignment is not universally reported]{Underspecifying alignment is not universally reported}\label{underspecifying-alignment-is-not-universally-reported}

The Standard is clear when it comes to underspecifying
alignment{\cprotect\footnote{\textbf{{cpp11}}, section 7.6.2, ``Alignment Specifier," paragraph~5, pp. 179}}:
\begin{quote}
The combined effect of all \textit{alignment-specifiers} in a declaration
shall not specify an alignment that is less strict than the alignment
that would be required for the entity being declared if all
\textit{alignment-specifiers} were omitted (including those in other
declarations).
\end{quote}
The compiler is required to honor the
specified value if it is a \textbf{fundamental
alignment},{\cprotect\footnote{``If the constant expression evaluates to
a fundamental alignment, the alignment requirement of the declared
entity shall be the specified fundamental alignment'': \textbf{cpp11}, section~7.6.2, ``Alignment Specifier," paragraph~2, item~2, p. 178.}} so
imagining how this would lead to anything other than an ill-formed
program is difficult:

\begin{lstlisting}[language=C++]
alignas(4) void* p;              // (1) Error: (ù{\codeincomments{alignas(4)}}ù) is below minimum, 8.

struct alignas(2) S { int x; };  // (2) Error: (ù{\codeincomments{alignas(2)}}ù) is below minimum, 4.

struct alignas(2) T { };
struct alignas(1) U { T e; };    // (3) Error: (ù{\codeincomments{alignas(1)}}ù) is below minimum, 2.
\end{lstlisting}

\noindent Each of the three errors above are reported by Clang, but GCC
doesn't issue so much as a warning (let alone the required error) ---
even in the most pedantic warning mode. Thus, one could write a program,
involving statements like those above, that happens to work on one
platform (e.g., GCC) but fails to compile on another (e.g.,
Clang).{\cprotect\footnote{Underspecifying alignment is not reported at
all by GCC 10.1, using the
\texttt{-std=c++11} \texttt{-Wall} \texttt{-Wextra} \mbox{\texttt{-Wpedantic}}
flags. With the same set of options, Clang 10.0 produces a compilation
failure. MSVC v19.24 will produce a warning and ignore any alignment
  less than the minimum one.}}

\subsubsection[Incompatibly specifying alignment is \textbf{IFNDR}]{Incompatibly specifying alignment is \textbf{IFNDR}}\label{incompatibly-specifying-alignment-is-ifndr}

It is permissible to forward declare a user-defined type (UDT)
without an \texttt{alignas} specifier so long as all defining
declarations of the type have either no \texttt{alignas} specifier or
have the same one. Similarly, if any forward declaration of a
user-defined type has an \texttt{alignas} specifier, then all defining
declarations of the type must have the same specifier and that specifier
must be \emph{equivalent to} (not necessarily \emph{the same as}) that
in the forward declaration:

\begin{lstlisting}[language=C++]
struct Foo;                  // OK, does not specify an alignment
struct alignas(double) Foo;  // OK, must be equivalent to every definition
struct alignas(8) Foo;       // OK, all definitions must be identical.
struct alignas(8) Foo { };   // OK, equivalent to each decl. specifying (ù{\codeincomments{alignas}}ù)
struct Foo;                  // OK, has no effect
struct alignas(8) Foo;       // OK, has no effect; might warn after definition
\end{lstlisting}

\noindent Specifying an alignment in a forward declaration without specifying an
equivalent one in the defining declaration is \textbf{ill formed; no diagnostic
is required (IFNDR)} if the two declarations appear in distinct translation
units:

\begin{lstlisting}[language=C++]
struct alignas(4) Bar;      // OK, forward declaration
struct Bar { };             // error: missing (ù{\codeincomments{alignas}}ù) specifier

struct alignas(4) Baz;      // OK, forward declaration
struct alignas(8) Baz { };  // error: non-equivalent (ù{\codeincomments{alignas}}ù) specifier
\end{lstlisting}

\noindent Both of the errors above are flagged by Clang, but neither of them is
reported by GCC. Note that when the inconsistency occurs across
translation units, no mainstream compiler is likely to diagnose the
problem:

\begin{lstlisting}[language=C++]
// file1.cpp:
struct Bam { char ch; } bam, *p = &bam;

// file2.cpp:
struct alignas(int) Bam;  // Error: definition of (ù{\codeincomments{Bam}}ù) lacks alignment specifier.
extern Bam* p;            //        (no diagnostic required)
\end{lstlisting}

\noindent Any program incorporating both translation units above is
\textbf{ill formed, no diagnostic required}.

\subsubsection[Stricter alignment might reduce cache utilization]{Stricter alignment might reduce cache utilization}\label{stricter-alignment-might-reduce-cache-utilization}

User-defined types having artificially stricter alignments than would
naturally occur on the host platform means that fewer of them can fit
within any given level of physical cache within the hardware. Types
having data members whose alignment is artificially widened tend to be
larger and thus suffer the same lost cache utilization. As an
alternative to enforcing stricter alignment to avoid \textbf{false
sharing}, consider organizing a multithreaded program such that tight
clusters of repeatedly accessed objects are always acted upon by only a
single thread at a time, e.g., using local (arena) memory allocators;
see {\it\titleref{alignas-appendix}:} {\it\titleref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}} on page~\pageref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}.

\subsection[See Also]{See Also}\label{see-also}

\begin{itemize}
\item{Section~\ref{alignof}, ``\titleref{alignof}" — Safe C++11 feature that inspects the alignment of a given type}
\item{Section~\ref{attributes}, ``\titleref{attributes}" — Safe C++11 feature that shows how other attributes (following the conventional attribute notation) are used to annotate source code, improve error diagnostics, and implicitly code generation} %%% WORDS MISSING!
\end{itemize}

\subsection[Further Reading]{Further Reading}\label{further-reading}

None so far

\subsection[Appendix]{Appendix}\label{alignas-appendix}

\subsubsection[Natural Alignment]{Natural Alignment}\label{natural-alignment}

By default, fundamental, pointer, and enumerated types typically reside
on an address boundary that divides the size of the object; we refer to
such alignment as \textbf{natural alignment}{\cprotect\footnote{Sizes
and alignment shown here are typical but not specifically required by
the standard. On some platforms, one can request that all
types be \textbf{byte aligned}. While such a representation is more
compact, entities that span memory boundaries can require multiple
fetch operations leading to run times that are typically
significantly (sometimes as much as an order of magnitude) slower when
  run in this ``packed'' mode.}}:

\begin{lstlisting}[language=C++]
char   c;  // size 1; alignment 1; boundaries: 0x00, 0x01, 0x02, 0x03, ...
short  s;  // size 2; alignment 2: boundaries: 0x00, 0x02, 0x04, 0x06, ...
int    i;  // size 4; alignment 4; boundaries: 0x00, 0x04, 0x08, 0x0c, ...
float  f;  // size 4; alignment 4; boundaries: 0x00, 0x04, 0x08, 0x0c, ...
double d;  // size 8; alignment 8; boundaries: 0x00, 0x08, 0x10, 0x18, ...
\end{lstlisting}

\noindent For aggregates (including arrays) or user-defined types, the alignment
is typically that of the most strictly aligned subelement:

\begin{lstlisting}[language=C++]
struct S0
{
    char a;  // size 1; alignment 1
    char b;  // size 1; alignment 1
    int  c;  // size 4; alignment 4
};           // size 8; alignment 4

struct S1
{
    char a;  // size  1; alignment 1
    int  b;  // size  4; alignment 4
    char c;  // size  1; alignment 1
};           // size 12; alignment 4

struct S2
{
    int  a;  // size 4; alignment 4
    char b;  // size 1; alignment 1
    char c;  // size 1; alignment 1
};           // size 8; alignment 4

struct S3
{
    char a;  // size 1; alignment 1
    char b;  // size 1; alignment 1
};           // size 2; alignment 1

struct S4
{
    char a[2];  // size 2; alignment 1
};              // size 2; alignment 1
\end{lstlisting}

\noindent Size and alignment behave similarly with respect to \textbf{structural
inheritance}:

\begin{lstlisting}[language=C++]
struct D0 : S0
{
    double d;  // size  8; alignment 8
};             // size 16; alignment 8

struct D1 : S1
{
    double d;  // size  8; alignment 8
};             // size 24; alignment 8

struct D2 : S2
{
    int d;  // size  4; alignment 4
};          // size 12; alignment 4

struct D3 : S3
{
    int d;  // size 4; alignment 4
};          // size 8; alignment 4

struct D4 : S4
{
    char d;  // size 1; alignment 1
};           // size 3; alignment 1
\end{lstlisting}

\noindent Finally, virtual functions invariably introduce an implicit
virtual-table-pointer member having a size and alignment corresponding
to that of a memory address (e.g., 4 or 8) on the host platform:

\begin{lstlisting}[language=C++]
struct S5
{
    virtual ~S5();
};                   // size 8; alignment 8

struct D5 : S5
{
    char d;  // size  1; alignment 1
};           // size 16; alignment 8
\end{lstlisting}


\subsubsection[Cache lines; L1, L2, and L3 cache; pages; and virtual memory]{Cache lines; L1, L2, and L3 cache; pages; and virtual memory}\label{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}

Modern computers are highly complex systems, and a detailed
understanding of their intricacies is unnecessary to achieve most of
the performance benefits. Still, certain general themes and
rough thresholds aid in understanding how to squeeze just a bit
more out of the underlying hardware. In this section, we sketch
fundamental concepts that are common to all modern computer hardware;
although the precise details will vary, the general ideas remain
essentially the same.

In its most basic form, a computer consists of central processing unit
(CPU) having internal registers that access main memory (MM).
Registers in the CPU (on the order of hundreds of bytes) are among the
fastest forms of memory, while main memory (typically many gigabytes) is
orders of magnitude slower. An almost universally observed phenomenon is
that of \textbf{locality of reference}, which suggests that data that
resides in close proximity (in the virtual address space) is more likely
to be accessed together in rapid succession than more distant data.

To exploit the phenomenon of \textbf{locality of reference}, computers
introduce the notion of a cache that, while much faster than main
memory, is also much smaller. Programs that attempt to amplify
\textbf{locality of reference} will, in turn, often be rewarded with
faster run times. The organization of a cache and, in fact, the number of
levels of cache (e.g., L1, L2, L3,$\ldots$) will vary, but the basic
design parameters are, again, more or less the same. A given level of
cache will have a certain total size in bytes (invariably an integral
power of two). The cache will be segmented into what are called
\textbf{cache lines} whose size (a smaller power of two) divides that of
the cache itself. When the CPU accesses main memory, it first looks to
see if that memory is in the cache; if it is, the value is returned
quickly (known as a \textbf{cache hit}). Otherwise, the cache line(s)
containing that data is (are) fetched (from the next higher level of cache
or from main memory) and placed into the cache (known as a \textbf{cache
miss}), possibly ejecting other less recently used
ones.{\cprotect\footnote{Conceptually, the cache is often thought of as
being able to hold any arbitrary subset of the most recently accessed
cache lines. This kind of cache is known as \textbf{fully
associative}. Although it provides the best hit rate, a \textbf{fully
associative} cache requires the most power along with significant
additional chip area to perform the fully parallel lookup. \textbf{Direct-mapped} cache associativity is at the
other extreme. In direct mapped, each memory location has exactly one location
available to it in the cache. If another memory location mapping to
that location is needed, the current cache line must be flushed from
the cache. Although this approach has the lowest hit rate, lookup
times, chip area, and power consumption are all minimized (optimally).
Between these two extremes is a continuum that is referred to as
\textbf{set associative}. A \textbf{set associate} cache has more than
  one (typically 2, 4, or 8; see \textbf{solihin15}, section~5.2.1, ``Placement Policy," pp. 136--141, and \textbf{hruska20})
  location in which each memory location in main memory can reside.
  Note that, even with a relatively small $N$, as $N$ increases, an $N$-way
  \textbf{set associative} cache quickly approaches the hit rate of a fully
  associative cache at greatly reduced collateral cost; for most
  software-design purposes, any loss in hit rate due to set
  associativity of a cache can be safely ignored.}}

Data residing in distinct cache lines is physically independent and can
be written concurrently by multiple threads. Logically unrelated data
residing in the same cache line, however, is nonetheless physically
coupled; two threads that write to such logically unrelated data will find
themselves synchronized by the hardware. Such unexpected and typically
undesirable sharing of a cache line by unrelated data acted upon by two
concurrent threads is known as \textbf{false sharing}. One way of
avoiding \textbf{false sharing} is to align such data on a cache-line
boundary, thus rendering accidental collocation of such data on the same
cache line impossible. Another (more broad-based) design approach that
avoids lowering cache utilization is to ensure that data acted upon by a
given thread is kept physically separate --- e.g., through the use of
local (arena) memory allocators.{\cprotect\footnote{\textbf{{lakos17}},
  \textbf{{lakos19}}, \textbf{{lakos22}}}}

Finally, even data that is not currently in cache but resides nearby in
MM can benefit from locality. The virtual address space, synonymous with
the size of a \texttt{void*} (typically 64-bits on modern general-purpose hardware), has historically well exceeded the physical memory
available to the CPU. The operating system must therefore maintain a
mapping (in main memory) from what is resident in physical memory and
what resides in secondary storage (e.g., on disc). In addition,
essentially all modern hardware provides a
\textbf{TLB}{\cprotect\footnote{A translation-lookaside buffer (TLB) is
a kind of address-translation cache that is typically part of a chip's
memory management unit (MMU). A TLB holds a recently accessed subset
of the complete mapping (itself maintained in MM) from virtual memory
address to physical ones. A TLB is used to reduce access time when the
requisite pages are already resident in memory; its size (e.g., 4K) is
capped at the number of bytes of physical memory (e.g., 32Gb) divided
by the number of bytes in each physical page (e.g., 8Kb), but could be
smaller. Because it resides on chip, is typically an order of
magnitude faster (SRAM versus DRAM), and requires only a single lookup
(as opposed to two or more when going out to MM), there is an enormous
  premium on minimizing TLB misses.}} that caches the addresses of the
most recently accessed physical pages, providing yet another advantage
to having the \textbf{working set} (i.e., the current set of frequently
accessed pages) remain small and densely packed with relevant
data.{\cprotect\footnote{Note that memory for handle-body
types (e.g., \texttt{std::vector} or \texttt{std::deque}) and
especially node-based containers (e.g., \texttt{std::map} and
\texttt{std::unordered\_map}), originally allocated within a single
page, can --- through deallocation and reallocation (or even move
operations) --- become scattered across multiple (perhaps many)
 pages, thus causing what was originally a relatively small \textbf{working set}
to no longer fit within physical memory. This phenomenon, known as
\textbf{diffusion} (which is a distinct concept from
\textbf{fragmentation}), is what typically leads to a substantial
runtime performance degradation (due to \textbf{thrashing}) in large,
long-running programs. Such \textbf{diffusion} can be mitigated by
judicious use of local arena memory allocators (and deliberate
avoidance of \textbf{move operations} across disparate localities of
  frequent memory usage).}} What's more, dense working sets, in addition
to facilitating hits for repeat access, increase the likelihood that
data that is coresident on a page (or cache line) will be needed soon
(i.e., in effect acting as a prefetch).{\cprotect\footnote{We sometimes
lightheartedly refer to the beneficial prefetch of unrelated data that
is accidentally needed subsequently (e.g., within a single thread) due
to high locality within a cache line (or a physical page) as
  \textbf{true sharing}.}} Table~\ref{table-alignas-appendix} provides a summary of typical physical parameters found in modern computers today.

%%%%%%TODO: TBD: @Lori: Format this as a figure with a caption. @jslakos: Double-check accuracy of values.

\begin{table}[h!]
\begin{center}
\begin{threeparttable}
\caption{Various sizes and access speeds of typical memory for modern \mbox{computers}}\label{table-alignas-appendix} \vspace{1.5ex}
{\small \begin{tabular}{c|c|c}\thickhline
\rowcolor[gray]{.9}    {\sffamily\bfseries Memory Type} & {\sffamily\bfseries Typical Memory Size (Bytes)} & {\sffamily\bfseries Typical Access Times}\\\hline
CPU Registers & 512 \ldots~2048 & $\sim$250ps\\ \hline
Cache Line  & 64 \ldots~256 & NA\\ \hline
L1 Cache & 16Kb \ldots~64Kb & $\sim$1ns\\ \hline
L2 Cache & 1Mb \ldots~2Mb & $\sim$10ns\\ \hline
L3 Cache & 8Mb \ldots~32Mb & $\sim$80ns--120ns\\ \hline
L4 Cache & 32Mb \ldots~128Mb & $\sim$100ns--200ns\\ \hline
Set Associativity  &  2 \ldots~64 & NA\\ \hline
TL & 4 words \ldots~65536 & 10ns \ldots~50ns\\ \hline
Physical Memory Page & 512 \ldots~8192 & 100ns \ldots~500ns\\ \hline
\rule{0pt}{3.5mm}Virtual Memory & $2^{32}$ bytes \ldots~$2^{64}$ bytes & $\sim$10$\mu$s--50$\mu$s\\ \hline
Solid-State Disc (SSD) & 256Gb \ldots~16Tb & $\sim$25$\mu$s--100$\mu$s\\ \hline
Mechanical Disc & Huge & $\sim$5ms--10ms\\ \hline
Clock Speed & NA & $\sim$4GHz \\ \thickhline
\end{tabular}
}
\end{threeparttable}
    \end{center}
\end{table}
\clearpage

