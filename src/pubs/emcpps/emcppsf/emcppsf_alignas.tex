% 18 March 2021, revisions in and proofed; commands updated
% 18 March 2021, sent to Slava for a second review and sent to Josh for code review


\emcppsFeature{
    short={\lstinline!alignas!},
    tocshort={\TOCCode alignas},
    long={The {\SecCode alignas} Decorator},
    toclong={The \lstinline!alignas! Decorator},
    rhshort={\RHCode alignas},
}{alignas}
%\section[{\tt alignas}]{The {\SecCode alignas} Decorator\sectionmark{\RHCode alignas}}\label{alignas}\sectionmark{\RHCode alignas}
\setcounter{table}{0}
\setcounter{footnote}{0}
\setcounter{lstlisting}{0}

The \lstinline!alignas! storage specifier is used to strengthen
the \emcppsgloss{alignment} of a \lstinline!struct!, \lstinline!class!, \lstinline!union!, \lstinline!enum!, \emcppsgloss{variable}, or \emcppsgloss{data member}.

\subsection[Description]{Description}\label{description-alignas}

Each object type in C++ has an \emcppsgloss{alignment requirement} which restricts the addresses at which an object of that type is permitted to reside within the virtual-memory-address space. The \emcppsgloss{alignment requirement} is imposed by the object type on all objects of that type. The \lstinline!alignas! specifier provides a means of specifying a stricter alignment requirement than dictated by the type itself for (1) a particular variable of the type, (2) an individual data member of a \emcppsgloss[user defined type (UDT)]{user-defined type (UDT)}. \lstinline!alignas! can also be applied to a \emcppsgloss[user defined type (UDT)]{UDT} itself, but see \intraref{potential-pitfalls-alignas}{applying-alignas-to-a-type-might-be-misleading}.

\subsubsection[Supported alignments]{Supported alignments}\label{description-supported-alignments}

An alignment value is an integer of type \lstinline!std::size_t! that represent the number of bytes between the addresses at which a given object may be allocated.  All alignment values in C++ are always non-negative powers of two, and are divided into two categories depending whether they are larger than the alignment requirement of the \lstinline!std::max_align_t! type.  The \lstinline!std::max_align_t! type is a type whose alignment requirement is at least as strict as that of every \emcppsgloss{scalar type}.  If the alignment value is less than or equal to the alignment requirement of \lstinline!std::max_align_t!, it is a \emcppsgloss{fundamental alignment}; otherwise it is an \emcppsgloss{extended alignment}.  \lstinline!std::max_align_t! is typically an alias to the largest scalar type, which is \lstinline!long double! on most platforms, and its alignment requirement is usually 8 or 16.

\emcppsgloss[fundamental alignment]{Fundamental alignments} are required to be supported in \emph{all} contexts -- i.e., for variables with automatic, static, and dynamic storage durations, as well as for non-static data members of a class, and function arguments.  While all fundamental and pointer types have \emcppsgloss[fundamental alignment]{fundamental alignments}, their specific values are \emcppsgloss[implementation defined]{implementation defined} and may differ between platforms.  For example, the alignment requirement of type \lstinline!long! might be \lstinline!4! on MSVC and \lstinline!8! on GCC.

In contrast, whether \emph{any} \emcppsgloss{extended alignment} is supported at all, and if it is -- in which contexts -- is \emcppsgloss{implementation defined}. For example, the strictest supported \emcppsgloss{extended alignment} for a variable with static storage duration might be as large as $2^{28}$ or $2^{29}$ on or as small as $2^{13}$.\footnote{Implementations may warn when the alignment of a global object exceeds some maximal hardware threshold (such as the size of a physical memory page, e.g., 4096 or 8192).  For automatic variables (defined on the program stack), making alignment more restrictive than what would naturally be employed is seldom desired because at most one thread is able to access proximately located variables there unless explicitly passed in via address to separate threads; see \intraref{alignas-use-cases}{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}. Note that, in the case of i in the first code snippet on \pageref{}
[page 66---REVISIONS: pls tell me exactly what you're referring to and I'll add a label there, so we get an automatically updating page number], a conforming platform that did not support an extended alignment of 64 would be required to report an error at compile time.}

Since many aspects pertaining to the alignment requirements are \emcppsgloss{implementation defined}, we will use a specific platform to illustrate the behavior of \lstinline!alignas! throughout this section.  Accordingly, the examples below show the behavior observed for the \lstinline!Clang! compiler targetting desktop x86-64 Linux.

%The \texttt{alignas} specifier provides a means of further restricting
%the granularity at which (1) a particular object of arbitrary type, (2)
%a user-defined type (\texttt{class}, \texttt{struct}, \texttt{union}, or
%\texttt{enum}), or (3) an individual data member is permitted to reside
%within the virtual-memory-address space.

\subsubsection[Strengthening the alignment of a particular object]{Strengthening the alignment of a particular object}\label{restricting-the-alignment-of-a-particular-object}\label{strengthening-the-alignment-of-a-particular-object}

In its most basic form, \lstinline!alignas! specifier allows to strengthen the alignment requirement of a particular object. The desired alignment requirement is an \emcppsgloss{integral constant expression} provided as an argument to \lstinline!alignas!:

\begin{emcppslisting}
alignas(8) int i;   // OK, i is aligned on an 8 byte address boundary.
int j alignas(8), k; // OK, j is 8 byte aligned; alignment of k is unchanged.
\end{emcppslisting}

\noindent If more than one alignment pertains to a given object, the strictest alignment value is applied:

\begin{emcppslisting}
alignas(4) alignas(8) alignas(2) char m;  // OK, (ù{\codeincomments{m}}ù) is 8-byte aligned.
alignas(8) int n alignas(16);             // OK, (ù{\codeincomments{n}}ù) is 16-byte aligned.
\end{emcppslisting}

\noindent For a program to be \emcppsgloss{well formed}, a specified alignment value
must satisfy several\linebreak[4] \mbox{requirements}:

\begin{enumerate}
\item{Be either zero or a non-negative integral power of two of type \lstinline!std::size_t! (0, 1, 2, 4, 8, 16\dots).}
%\item{Be at least the minimum alignment\cprotect\footnote{The minimum alignment of an entity is the least restrictive memory-address boundary at which the entity can be placed and have the program continue to work properly. This value is platform dependent and often subject to compiler controls but, by default, is often well approximated by \textbf{natural alignment}; see \textit{\titleref{alignas-appendix}: \titleref{natural-alignment}} on page \pageref{natural-alignment}.} required by the decorated entity.}
\item{Be larger or equal to what the alignment requirement would be without \lstinline!alignas! specifier.}
\item{Be supported on the platform in the context in which the entity appears.}
%\cprotect\footnote{The notion of the largest supported alignment is characterized by both \textbf{maximal alignment} and the maximum \textbf{extended alignment}. \textbf{Maximal alignment} is defined as that most restrictive alignment that is valid in \emph{all} contexts on the current platform. All fundamental and pointer types necessarily have a minimal alignment that is less than or equal to \texttt{alignof(std::max\_align\_t)} — typically 8 or 16. Any alignment value greater than \textbf{maximal alignment} is an \textbf{extended alignment} value. Whether any extended alignment is supported (and in which contexts) is implementation defined. On typical platforms, extended alignment will often be as large as $2^{18}$ or $2^{19}$, however implementations may warn when the alignment of a global object exceeds some maximal hardware threshold (such as the size of a physical memory page, e.g., 4096 or 8192). For \textbf{automatic variables} (defined on the program stack), making alignment more restrictive than what would naturally be employed  is seldom desired because at most one thread is able to access proximately located variables there unless explicitly passed in via address to separate threads; see \textit{\titleref{alignas-use-cases}: \titleref{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}} on page~\pageref{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}. Note that, in the case of \texttt{i} in the first code snippet on page~\pageref{restricting-the-alignment-of-a-particular-object}, a conforming platform that did not support an extended alignment of 64 would be required to report an error at compile time.}
\end{enumerate}

\noindent Additionally, if the specified alignment value is zero, the
\lstinline!alignas! specifier is ignored:

%\begin{lstlisting}[language=C++]
%// Static variables declared at namespace scope
%alignas(32) int i0;  // OK, aligned on a 32-byte boundary (extended alignment)
%alignas(16) int i1;  // OK, aligned on a 16-byte boundary (maximum alignment)
%alignas(8)  int i2;  // OK, aligned on an 8-byte boundary
%alignas(7)  int i3;  // Error, not a power of two
%alignas(4)  int i4;  // OK, no change to alignment boundary
%alignas(2)  int i5;  // Error, less than minimum alignment on this platform
%alignas(0)  int i6;  // OK, (ù{\codeincomments{alignas}}ù) specifier ignored
%
%alignas(1024 * 16) int i7;
%    // OK, might warn: e.g., exceeds (physical) page size on current platform
%
%alignas(1024 * 1024 * 512) int i8;
%    // (likely) compile-time error: e.g., exceeds maximum size of object file
%
%alignas(8) char buf[128];  // create 8-byte-aligned, 128-byte character buffer
%
%void f()
%{
%    // automatic variables declared at function scope
%    alignas(4)  double e0;  // Error, less than minimum alignment on this platform
%    alignas(8)  double e1;  // OK, no-change to (8-byte) alignment boundary
%    alignas(16) double e2;  // OK, aligned to maximum (fundamental) alignment value
%    alignas(32) double e3;  // OK, maximum alignment value exceeded; might warn
%}
%\end{lstlisting}
\begin{emcppslisting}
// Static variables declared at namespace scope
alignas(32) int i0; // OK, 32-byte aligned (extended alignment)
alignas(16) int i1; // OK, 16-byte aligned (strictest fundamental alignment)
alignas(8)  int i2; // OK,  8-byte aligned (fundamental alignment)
alignas(7)  int i3; // Error, not a power of two
alignas(4)  int i4; // OK, no change to alignment requirement
alignas(2)  int i5; // Error, less than alignment would be without (ù{\codeincomments{alignas}}ù)
alignas(0)  int i6; // OK, (ù{\codeincomments{alignas}}ù) specifier ignored

alignas(1024 * 16) int i7;
    // OK, might warn on other platforms: e.g., exceeds physical page size

alignas(1 << 30) int i8;
    // Error, exceeds maximum supported extended alignment

alignas(8) char buf[128]; // OK, 8-byte-aligned, 128-byte character buffer

void f()
{
  // automatic variables declared at function scope
  alignas(4)  double e0; // Error, less than alignment would be without (ù{\codeincomments{alignas}}ù)
  alignas(8)  double e1; // OK, no change to (8-byte) alignment requirement
  alignas(16) double e2; // OK, 16-byte aligned (fundamental alignment)
  alignas(32) double e3; // OK, 32-byte aligned (extended alignment)
}
\end{emcppslisting}



\subsubsection[Strengthening the alignment of individual data members]{Strengthening the alignment of individual data members}\label{restricting-the-alignment-of-individual-data-members}\label{strengthening-the-alignment-of-individual-data-members}

Within a user-defined type (\lstinline!class!, \lstinline!struct!, or
\lstinline!union!), using the
\lstinline!alignas! keyword to specify the alignments of individual data
members is possible:

\begin{emcppslisting}
struct T2
{
    alignas(8)  char   x;  // size   1; alignment 8
    alignas(16) int    y;  // size   4; alignment 16
    alignas(64) double z;  // size   8; alignment 64
};  // size 128; alignment 64
\end{emcppslisting}

\noindent The effect here is the same as if we had added the padding explicitly
and then set the alignment of the structure overall:

\begin{emcppslisting}
struct alignas(64) T3
{
    char   x;      // size   1; alignment 8
    char   a[15];  // padding
    int    y;      // size   4; alignment 16
    char   b[44];  // padding
    double z;      // size   8; alignment 64
    char   c[56];  // padding (optional)
};  // size 128; alignment 64
\end{emcppslisting}

\noindent Again, if more than one alignment specifier pertains to a given data member,
the strictest applicable alignment value is applied:

\begin{emcppslisting}
struct T4
{
    alignas(2) char
        c1 alignas(1),  // size 1; alignment 2
        c2 alignas(2),  // size 1; alignment 2
        c4 alignas(4);  // size 1; alignment 4
};                      // size 8; alignment 4
\end{emcppslisting}

\subsubsection[Strengthening the alignment of a user-defined type]{Strengthening the alignment of a user-defined type}\label{restricting-the-alignment-of-a-user-defined-type}
\label{strengthening-the-alignment-of-a-user-defined-type}

The \lstinline!alignas! specifier can also be used to specify alignment for
user-defined types (UDTs), such as a \lstinline!class!, \lstinline!struct!,
\lstinline!union!, or \lstinline!enum!. When specifying the alignment of a UDT,
 the \lstinline!alignas! keyword is placed \emph{after} the
type specifier (e.g., \lstinline!class!) and just before the name of the
type (e.g., \lstinline!C!):

%\begin{lstlisting}[language=C++]
%class alignas(2)  C { };  // OK, aligned on a 2-byte boundary; size = 2
%struct alignas(4) S { };  // OK, aligned on a 4-byte boundary; size = 4
%union alignas(8)  U { };  // OK, aligned on an 8-byte boundary; size = 8
%enum alignas(16)  E { };  // OK, aligned on a 16-byte boundary; size = 4
%\end{lstlisting}
\begin{emcppslisting}
class  alignas( 2) C { }; // OK, aligned on a  2-byte boundary; size = 2
struct alignas( 4) S { }; // OK, aligned on a  4-byte boundary; size = 4
union  alignas( 8) U { }; // OK, aligned on an 8-byte boundary; size = 8
enum   alignas(16) E { }; // OK, aligned on a 16-byte boundary; size = 4
\end{emcppslisting}

\noindent Notice that, for each of \lstinline!class!, \lstinline!struct!, and
\lstinline!union! above, the \lstinline!sizeof! objects of that type increased
to match the alignment; in the case of the \lstinline!enum!, however, the
size remains that of the default \emcppsgloss[underlying type (UT)]{underlying type} (e.g., 4
bytes) on the current platform.{\cprotect\footnote{When \lstinline!alignas!
is applied to an enumeration \lstinline!E!, the Standard does not
indicate whether padding bytes are added to \lstinline!E!'s object
representation or not, affecting the result of \lstinline!sizeof(E)!. The
implementation variance resulting from this lack of clarity in the
  Standard was captured in \cite{miller17}. The outcome of the core
  issue was to completely remove permission for \lstinline!alignas! to be
  applied to enumerations (see \cite{iso18a}). Therefore, conforming implementations will
  eventually stop accepting the \lstinline!alignas! specifier on
  enumerations in the future.}}

Again, specifying an alignment that is less than what be without the \lstinline!alignas! specifier is ill formed:

\begin{emcppslisting}
struct alignas(2) T0 { int i; };
    // Error, Alignment of (ù{\codeincomments{T0}}ù) (2) is less than that of (ù{\codeincomments{int}}ù) (4).
struct alignas(1) T1 { C c; };
    // Error, Alignment of (ù{\codeincomments{T1}}ù) (1) is less than that of (ù{\codeincomments{C}}ù) (2).
\end{emcppslisting}



\subsubsection[Matching the alignment of another type]{Matching the alignment of another type}\label{matching-the-alignment-of-another-type}

The \lstinline!alignas! specifier also accepts (as an argument) a type
identifier. In its alternate form, \lstinline!alignas(T)! is strictly
equivalent to \lstinline!alignas(alignof(T))! (see \featureref{\locationc}{alignof}):

\begin{emcppslisting}
alignas(int) char c;  // equivalent to (ù{\codeincomments{alignas(alignof(int)) char c;}}ù)
\end{emcppslisting}


\subsection[Use Cases]{Use Cases}\label{alignas-use-cases}

\subsubsection[Creating a sufficiently aligned object buffer]{Creating a sufficiently aligned object buffer}\label{creating-a-sufficiently-aligned-object-buffer}

When writing low-level, system-infrastructure code, constructing an object within a raw buffer is sometimes useful. As a minimal
example, consider a function that uses a local character buffer to
create an object of type \lstinline!std::complex<long!~\lstinline!double>! on
the program stack using placement \lstinline!new!:

\begin{emcppslisting}
#include <complex>  // (ù{\codeincomments{std::complex}}ù)

void f()
{
    // ...
    char objectBuffer[sizeof(std::complex<long double>)];  // BAD IDEA
    // ...
    new (objectBuffer) std::complex<long double>(1.0, 0.0);  // Might dump core!
    // ...
}
\end{emcppslisting}

\noindent The essential problem with the code above is that \lstinline!objectBuffer!,
being an array of characters (each having an alignment of 1), is itself
byte aligned. The compiler is therefore free to place it on any address
boundary. On the other hand, \lstinline!std::complex<long!~\lstinline!double>! is an aggregate consisting of two \lstinline!long!~\lstinline!double! objects
and therefore necessarily requires (at least) the same strict alignment
(typically 16) as the two \lstinline!long!~\lstinline!double! objects it comprises. Previous
solutions to this problem involved creating a \lstinline!union! of the
object buffer and some maximally aligned type (e.g.,
\lstinline!std::max_align_t!):

\begin{emcppslisting}
#include <complex>  // (ù{\codeincomments{std::complex}}ù)
#include <cstddef>  // (ù{\codeincomments{std::max\_align\_t}}ù)

void f()
{
    // ...

    union {                                              // awkward workaround
        std::max_align_t dummy;  // (ù{\codeincomments{typedef}}ù) to maximally aligned type
        char objectBuffer[sizeof(std::complex<long double>)];
    } objectBuffer;

    // ...

    new (&objectBuffer) std::complex<long double>(1.0, 0.0);  // OK

    // ...
}
\end{emcppslisting}

\noindent Using the alternate syntax for \lstinline!alignas!, we can avoid gratuitous
complexity and just state our intentions explicitly:

\begin{emcppslisting}
#include <complex>  // (ù{\codeincomments{std::complex}}ù)
void f()
{
    // ...

    alignas(std::complex<long double>) char objectBuffer[
                              sizeof(std::complex<long double>)];  // GOOD IDEA

    // ...

    new (objectBuffer) std::complex<long double>(1.0, 0.0);  // OK

    // ...
}
\end{emcppslisting}


\subsubsection[Ensuring proper alignment for architecture-specific instructions]{Ensuring proper alignment for architecture-specific instructions}\label{ensuring-proper-alignment-for-architecture-specific-instructions}

Architecture-specific instructions or compiler intrinsics might require
the data they act on to have a specific alignment. One example of such
intrinsics is the \emph{Streaming SIMD Extensions (SSE)}\footnote{\cite{inteliig}, ``Technologies: SSE"} instruction set available on the x86
architecture. SSE instructions operate on groups of four 32-bit
single-precision floating-point numbers at a time, which are required to
be 16-byte aligned.{\cprotect\footnote{``Data must be
16-byte aligned when loading to and storing from the 128-bit XMM
  registers used by SSE/SSE2/SSE3/SSSE3'': see \cite{{intel16}},
  section 4.4.4, ``Data Alignment for 128-Bit Data," pp. 4-19--4-20.}} The
\lstinline!alignas! specifier can be used to create a type satisfying this requirement:

\begin{emcppslisting}[emcppsbatch=e1]
struct SSEVector
{
    alignas(16) float d_data[4];
};
\end{emcppslisting}

\noindent Each object of the \lstinline!SSEVector! type above is guaranteed always to
be aligned to a 16-byte boundary and can therefore be safely (and
conveniently) used with SSE intrinsics:

\begin{emcppslisting}[emcppsbatch=e1]
#include <cassert>     // standard C (ù{\codeincomments{assert}}ù) macro
#include <xmmintrin.h> // (ù{\codeincomments{\_\_m128}}ù) and (ù{\codeincomments{\_mm\_XXX}}ù) functions

void f()
{
    const SSEVector v0 = {0.0f, 1.0f, 2.0f, 3.0f};
    const SSEVector v1 = {10.0f, 10.0f, 10.0f, 10.0f};

    __m128 sseV0 = _mm_load_ps(v0.d_data);
    __m128 sseV1 = _mm_load_ps(v1.d_data);
        // (ù{\codeincomments{\_mm\_load\_ps}}ù) requires the given (ù{\codeincomments{float}}ù) array to be 16-byte aligned.
        // The data is loaded into a dedicated 128-bit CPU register.

    __m128 sseResult = _mm_add_ps(sseV0, sseV1);
        // sum two 128-bit registers; typically generates an (ù{\codeincomments{addps}}ù) instruction

    SSEVector vResult;
    _mm_store_ps(vResult.d_data, sseResult);
        // Store the result of the sum back into a (ù{\codeincomments{float}}ù) array.

    assert(vResult.d_data[0] == 10.0f);
    assert(vResult.d_data[1] == 11.0f);
    assert(vResult.d_data[2] == 12.0f);
    assert(vResult.d_data[3] == 13.0f);
}
\end{emcppslisting}


\subsubsection[Avoiding false sharing among distinct objects in a multi-threaded program]{Avoiding false sharing among distinct objects in a multi-threaded program}\label{avoiding-false-sharing-among-distinct-objects-in-a-multi-threaded-program}

In the context of an application where multithreading has been employed
to improve performance, seeing
a previously single-threaded workflow become even less performant after
a parallelization attempt can be surprising (and disheartening). One possible insidious cause of such
disappointing results comes from \emcppsgloss{false sharing} --- a situation
in which multiple threads unwittingly harm each other's performance
while writing to logically independent variables that happen to reside
on the same \emcppsgloss{cache line}; see \intraref{alignas-appendix}{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}.

As a simple illustration of the potential
performance degradation resulting from \emcppsgloss{false sharing}, consider
a function that spawns separate threads to repeatedly increment
(concurrently) logically distinct variables that happen to reside in
close proximity on the program stack:

\begin{emcppslisting}
#include <thread>  // (ù{\codeincomments{std::thread}}ù)

void incrementJob(int* p);
    // Repeatedly increment (ù{\codeincomments{*p}}ù) a large, fixed number of times;
    // periodically write its current value to (ù{\codeincomments{target}}ù).

void f()
{
    int i0 = 0;  // Here, (ù{\codeincomments{i0}}ù) and (ù{\codeincomments{i1}}ù) likely share the same cache line,
    int i1 = 0;  // i.e., byte-aligned memory block on the program stack.

    std::thread t0(&incrementJob, &i0);
    std::thread t1(&incrementJob, &i1);
        // Spawn two parallel jobs incrementing the respective variables.

    t0.join();
    t1.join();
        // Wait for both jobs to be completed.
}
\end{emcppslisting}

\noindent In the simplistic example above, the proximity in memory between
\lstinline!i0! and \lstinline!i1! can result in their belonging to the same
\emcppsgloss{cache line}, thus leading to \emcppsgloss{false sharing}. By
using \lstinline!alignas! to strengthen the alignment requirement of both integers to the cache line size, we
ensure that the two variables reside on distinct cache lines:

%\begin{lstlisting}[language=C++]
%// ...
%
%void f()
%{
%    alignas(64) int i0 = 0;   // Assuming a cache line on this platform is 64
%    alignas(64) int i1 = 0;   // bytes, (ù{\codeincomments{i0}}ù) and (ù{\codeincomments{i1}}ù) will be on separate ones.
%
%    // ...
%\end{lstlisting}
\begin{emcppslisting}[emcppsbatch=e2]
// ...

enum { k_CACHE_LINE_SIZE = 64 };  // A cache line on this platform is 64 bytes

void f()
{
    alignas(k_CACHE_LINE_SIZE) int i0 = 0; // (ù{\codeincomments{i1}}ù) and (ù{\codeincomments{i2}}ù) are on separate
    alignas(k_CACHE_LINE_SIZE) int i1 = 0; // cache lines

    // ...
}
\end{emcppslisting}

\noindent As an empirical demonstration of the effects of \emcppsgloss{false sharing},
a benchmark program repeatedly calling \lstinline!f! completed its
execution seven times faster on average when compared to the same
program without use of \lstinline!alignas!.{\cprotect\footnote{The benchmark
program was compiled using Clang 11.0.0 using \lstinline!-Ofast!,
\lstinline!-march=native!, and \mbox{\lstinline!-std=c++11!}. The program was then
executed on a machine running Windows 10 x64, equipped with an Intel
Core i7-9700k CPU (8 cores, 64-byte cache line size). Over the
course of multiple runs, the version of the benchmark without
\lstinline!alignas! took 18.5967ms to complete (on average), while the
version with \lstinline!alignas! took 2.45333ms to complete (on average).
  See \textbf{{[PRODUCTION: CODE PROVIDED WITH BOOK] alignasbenchmark}} for the source code of the program.}} Note that because supported extended alignments are implementation defined, using \lstinline!alignas! is not a strictly portable solution. Opting for less elegant padding approach instead of \lstinline!alignas! might be preferrable for portability.

\subsubsection[Avoiding false sharing within a single thread-aware object]{Avoiding false sharing within a single thread-aware object}\label{avoiding-false-sharing-within-a-single-thread-aware-object}

A real-world scenario where the need for preventing \emcppsgloss{false
sharing} is fundamental occurs in the implementation of high-performance
concurrent data structures. As an example, a thread-safe ring buffer
might make use of \lstinline!alignas! to ensure that the indices of the
head and tail of the buffer are aligned at the start of a cache line
(typically 64, 128, or 256 bytes),\footnote{In C++17, one can portably retrieve the minimum offset between two objects that avoids false sharing through the \lstinline!std::hardware_destructive_interference_size! constant defined in the \lstinline!<new>! header.}  thereby preventing them from
occupying the same one.

\begin{emcppslisting}[emcppsbatch=e2]
#include <atomic>  // (ù{\codeincomments{std::atomic}}ù)
class ThreadSafeRingBuffer
{
    alignas(k_CACHE_LINE_SIZE) std::atomic<std::size_t> d_head;
    alignas(k_CACHE_LINE_SIZE) std::atomic<std::size_t> d_tail;

    // ...
};
\end{emcppslisting}

\noindent Not aligning \lstinline!d_head! and \lstinline!d_tail! (above) to the CPU
cache size might result in poor performance of the
\lstinline!ThreadSafeRingBuffer! because CPU cores that need to access only one
of the variables will inadvertently load the other one as well,
triggering expensive hardware-level coherency mechanisms between the
cores' caches. On the other hand, specifying such substantially stricter
alignment on consecutive data members necessarily increases the size of
the object; see \intraref{potential-pitfalls-alignas}{stricter-alignment-might-reduce-cache-utilization}.
%{\it\titleref{potential-pitfalls}:} {\it\titleref{stricter-alignment-might-reduce-cache-utilization}} on page~\pageref{stricter-alignment-might-reduce-cache-utilization}.

\subsection[Potential Pitfalls]{Potential Pitfalls}\label{potential-pitfalls-alignas}

\subsubsection[Underspecifying alignment is not universally reported]{Underspecifying alignment is not universally reported}\label{underspecifying-alignment-is-not-universally-reported}

The Standard is clear when it comes to underspecifying
alignment{\cprotect\footnote{\cite{{cpp11}}, section 7.6.2, ``Alignment Specifier," paragraph~5, pp. 179}}:
\begin{quote}
The combined effect of all \emph{alignment-specifiers} in a declaration
shall not specify an alignment that is less strict than the alignment
that would be required for the entity being declared if all
\emph{alignment-specifiers} were omitted (including those in other
declarations).
\end{quote}
The compiler is required to honor the
specified value if it is a \emcppsgloss{fundamental
alignment},{\cprotect\footnote{``If the constant expression evaluates to
a fundamental alignment, the alignment requirement of the declared
entity shall be the specified fundamental alignment'': \cite{cpp11}, section~7.6.2, ``Alignment Specifier," paragraph~2, item~2, p. 178.}} so
imagining how this would lead to anything other than an ill-formed
program is difficult:

\begin{emcppslisting}
alignas(4) void* p;              // Error, (ù{\codeincomments{alignas(4)}}ù) is below minimum, 8.

struct alignas(2) S { int x; };  // Error, (ù{\codeincomments{alignas(2)}}ù) is below minimum, 4.

struct alignas(2) T { };
struct alignas(1) U { T e; };    // Error, (ù{\codeincomments{alignas(1)}}ù) is below minimum, 2.
\end{emcppslisting}

\noindent Each of the three errors above are reported by Clang. MSVC and ICC issue a warning, whereas
 GCC
provides no diagnostic at all ---
even in the most pedantic warning mode. Thus, one could write a program,
involving statements like those above, that happens to work on one
platform (e.g., GCC) but fails to compile on another (e.g.,
Clang).{\cprotect\footnote{Underspecifying alignment is not reported at
all by GCC 10.2, using the
\lstinline!-std=c++11! \lstinline!-Wall! \lstinline!-Wextra! \mbox{\lstinline!-Wpedantic!}
flags. This behavior is reported as a compiler defect; see \cite{wakely15}. With the same set of options, Clang 10.1 produces a compilation
failure. ICC 2021.1.2 and MSVC v19.28 will produce a warning and ignore any alignment
  less than the minimum one.}}

\subsubsection[Incompatibly specifying alignment is IFNDR]{Incompatibly specifying alignment is IFNDR}\label{incompatibly-specifying-alignment-is-ifndr}

It is permissible to forward declare a user-defined type (UDT)
without an \lstinline!alignas! specifier so long as all defining
declarations of the type have either no \lstinline!alignas! specifier or
have the same one. Similarly, if any forward declaration of a
user-defined type has an \lstinline!alignas! specifier, then all defining
declarations of the type must have the same specifier and that specifier
must be \emph{equivalent to} (not necessarily \emph{the same as}) that
in the forward declaration:

\begin{emcppslisting}
struct Foo;                  // OK, does not specify an alignment
struct alignas(double) Foo;  // OK, must be equivalent to every definition
struct alignas(8) Foo;       // OK, all definitions must be identical.

struct alignas(8) Foo { };   // OK, def. equiv. to each decl. specifying alignment

struct Foo;                  // OK, has no effect
struct alignas(8) Foo;       // OK, has no effect; might warn after definition
\end{emcppslisting}

\noindent Specifying an alignment in a forward declaration without specifying an
equivalent one in the defining declaration is \emcppsgloss{ill formed, no diagnostic
required (IFNDR)} if the two declarations appear in distinct translation
units:

\begin{emcppslisting}
struct alignas(4) Bar;      // OK, forward declaration
struct Bar { };             // Error, missing (ù{\codeincomments{alignas}}ù) specifier

struct alignas(4) Baz;      // OK, forward declaration
struct alignas(8) Baz { };  // Error, non-equivalent (ù{\codeincomments{alignas}}ù) specifier
\end{emcppslisting}

\noindent Both of the errors above are flagged by Clang. MSVC and ICC warn on the first one and produce an error on the second one, whereas neither of them is
reported by GCC. Note that when the inconsistency \emph{occurs across
translation units}, no mainstream compiler is likely to diagnose the
problem:

\begin{emcppslisting}
// file1.cpp
struct Bam { char ch; } bam, *p = &bam;

// file2.cpp
struct alignas(int) Bam;  // Error, definition of (ù{\codeincomments{Bam}}ù) lacks alignment specifier.
extern Bam* p;            //        (no diagnostic required)
\end{emcppslisting}

\noindent Any program incorporating both translation units above is
\emcppsgloss[ill formed, no diagnostic required (IFNDR)]{IFNDR}.

\subsubsection[Applying \lstinline!alignas! to a \emph{type} might be misleading]{Applying {\SubsubsecCode alignas} to a {\sfbsubsubsecitalRomeo type} might be misleading}\label{applying-alignas-to-a-type-might-be-misleading}

When applying the \lstinline!alignas! specifier to a user-defined type having no base classes, one might be convinced that it is equivalent to applying \lstinline!alignas! to its first declared data member:

\begin{emcppslisting}
struct S0 {
    alignas(16) char d_buffer[128];  // guaranteed to be 16-byte aligned
                int  d_index;
};

struct alignas(16) S1 {
    char d_buffer[128];              // guaranteed to be 16-byte aligned
    int  d_index;
};
\end{emcppslisting}

Indeed, for all objects of the \lstinline!S0! and \lstinline!S1! types (above), their respective \lstinline!d_buffer! data members will be aligned on a 16-byte boundary. Such equivalency, however, holds only for \emcppsgloss{standard layout types}.  Adding a virtual function or even simply changing the access control for some of the data members\footnote{According to the C++20 Standard, compilers are allowed to reorder data members having different access control.  However, no compilers take advantage of this ability in practice, and C++23 might mandate that the data members are always laid out in declaration order; see \cite{balog20}.} might break this equivalency:

\begin{emcppslisting}
struct S2 {
    alignas(16) char d_buffer[128];  // guaranteed to be 16-byte aligned
                int  d_index;

    virtual ~S2();
};

struct alignas(16) S3 {
    char d_buffer[128];              // (ù{\emphincomments{NOT}}ù) guaranteed to be 16-byte aligned!
    int  d_index;

    virtual ~S3();
};

struct S4 {
    alignas(16) char d_buffer[128];  // guaranteed to be 16-byte aligned
private:
                int  d_index;
};

struct alignas(16) S5 {
    char d_buffer[128];              // (ù{\emphincomments{NOT}}ù) guaranteed to be 16-byte aligned!
private:
    int  d_index;
};
\end{emcppslisting}

Any code that relies on the \lstinline!d_buffer! member of instances of the \lstinline!S3! and \lstinline!S5! types (above) being 16-byte aligned is defective.

\subsubsection[Overlooking alternative approaches to avoid false sharing]{Overlooking alternative approaches to avoid false sharing}\label{stricter-alignment-might-reduce-cache-utilization}\label{overlooking-alternative-approaches-to-avoid-false-sharing}

User-defined types having artificially stricter alignments than would
naturally occur on the host platform means that fewer of them can fit
within any given level of physical cache within the hardware. Types
having data members whose alignment is artificially strengthened tend to be
larger and thus suffer the same lost cache utilization. As an
alternative to enforcing stricter alignment to avoid \emcppsgloss{false
sharing}, consider organizing a multithreaded program such that tight
clusters of repeatedly accessed objects are always acted upon by only a
single thread at a time, e.g., using local (arena) memory allocators;
see \intraref{alignas-appendix}{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}.
%{\it\titleref{alignas-appendix}:} {\it\titleref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}} on page~\pageref{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}.

\subsection[See Also]{See Also}\label{see-also}

\begin{itemize}
\item{%Section~\ref{alignof}, ``\titleref{alignof}" — Safe C++11 feature that
\seealsoref{alignof}{\seealsolocationc}inspects the alignment of a given type}
%\item{Section~\ref{attributes}, ``\titleref{attributes}" — Safe C++11 feature that shows how other attributes (following the conventional attribute notation) are used to annotate source code, improve error diagnostics, and implicitly code generation} %%% WORDS MISSING!
\end{itemize}

\subsection[Further Reading]{Further Reading}\label{further-reading}

None so far

\subsection[Appendix]{Appendix}\label{alignas-appendix}

\subsubsection[Natural Alignment]{Natural Alignment}\label{natural-alignment}

%By default, fundamental, pointer, and enumerated types typically reside
%on an address boundary that divides the size of the object; we refer to
%such alignment as \textbf{natural alignment}{\cprotect\footnote{Sizes
%and alignment shown here are typical but not specifically required by
%the standard. On some platforms, one can request that all
%types be \textbf{byte aligned}. While such a representation is more
%compact, entities that span memory boundaries can require multiple
%fetch operations leading to run times that are typically
%significantly (sometimes as much as an order of magnitude) slower when
%  run in this ``packed'' mode.}}:
%
%\begin{lstlisting}[language=C++]
%char   c;  // size 1; alignment 1; boundaries: 0x00, 0x01, 0x02, 0x03, ...
%short  s;  // size 2; alignment 2: boundaries: 0x00, 0x02, 0x04, 0x06, ...
%int    i;  // size 4; alignment 4; boundaries: 0x00, 0x04, 0x08, 0x0c, ...
%float  f;  // size 4; alignment 4; boundaries: 0x00, 0x04, 0x08, 0x0c, ...
%double d;  // size 8; alignment 8; boundaries: 0x00, 0x08, 0x10, 0x18, ...
%\end{lstlisting}

Many micro-architectures are optimized for working with data that has \emcppsgloss{natural alignment} --- that is that objects reside on an address boundary that divides their size rounded up to the nearest power of two.  With the additional restriction that no padding is allowed between C++ array elements, the alignment requirements of fundamental types are often equal to their respective size on most platforms:

\begin{emcppslisting}
char        c;  // size 1;  alignment 1;  boundaries: 0x00, 0x01, 0x02, ...
short       s;  // size 2;  alignment 2:  boundaries: 0x00, 0x02, 0x04, ...
int         i;  // size 4;  alignment 4;  boundaries: 0x00, 0x04, 0x08, ...
float       f;  // size 4;  alignment 4;  boundaries: 0x00, 0x04, 0x08, ...
double      d;  // size 8;  alignment 8;  boundaries: 0x00, 0x08, 0x10, ...
long double l;  // size 16; alignment 16; boundaries: 0x00, 0x10, 0x20, ...
\end{emcppslisting}

\noindent The alignment requirement of an array of objects is the same as that of its elements:

\begin{emcppslisting}
char  arrC[4];  // size 4; alignment 1
short arrS[4];  // size 8; alignment 2
\end{emcppslisting}

For user-defined types, compilers compute the alignment and add appropriate padding between the data members and after the last one such that all alignment requirements of the data members are satisfied and no padding would be required should an array of the type be created. Typically, this results in the alignment requirement of a \emcppsgloss[user defined type (UDT)]{UDT} be the same as that of the most strictly aligned non-static data member:

%For aggregates (including arrays) or user-defined types, the alignment
%is typically that of the most strictly aligned subelement:

\begin{emcppslisting}[emcppsbatch=e3]
struct S0
{
    char a;  // size 1; alignment 1
    char b;  // size 1; alignment 1
    int  c;  // size 4; alignment 4
};           // size 8; alignment 4

struct S1
{
    char a;  // size  1; alignment 1
    int  b;  // size  4; alignment 4
    char c;  // size  1; alignment 1
};           // size 12; alignment 4

struct S2
{
    int  a;  // size 4; alignment 4
    char b;  // size 1; alignment 1
    char c;  // size 1; alignment 1
};           // size 8; alignment 4

struct S3
{
    char a;  // size 1; alignment 1
    char b;  // size 1; alignment 1
};           // size 2; alignment 1

struct S4
{
    char a[2];  // size 2; alignment 1
};              // size 2; alignment 1
\end{emcppslisting}

\noindent Size and alignment behave similarly with respect to \emcppsgloss{structural
inheritance}:

\begin{emcppslisting}[emcppsbatch=e3]
struct D0 : S0
{
    double d;  // size  8; alignment 8
};             // size 16; alignment 8

struct D1 : S1
{
    double d;  // size  8; alignment 8
};             // size 24; alignment 8

struct D2 : S2
{
    int d;  // size  4; alignment 4
};          // size 12; alignment 4

struct D3 : S3
{
    int d;  // size 4; alignment 4
};          // size 8; alignment 4

struct D4 : S4
{
    char d;  // size 1; alignment 1
};           // size 3; alignment 1
\end{emcppslisting}

\noindent Finally, virtual functions and virtual base classes invariably introduce an implicit
virtual-table-pointer member having a size and alignment corresponding
to that of a memory address (e.g., 4 or 8) on the target platform:

\begin{emcppslisting}
struct S5
{
    virtual ~S5();
};                   // size 8; alignment 8

struct D5 : S5
{
    char d;  // size  1; alignment 1
};           // size 16; alignment 8
\end{emcppslisting}


\subsubsection[Cache lines; L1, L2, and L3 cache; pages; and virtual memory]{Cache lines; L1, L2, and L3 cache; pages; and virtual memory}\label{cache-lines,-l1,-l2,-and-l3-cache,-pages,-and-virtual-memory}

Modern computers are highly complex systems, and a detailed
understanding of their intricacies is unnecessary to achieve most of
the performance benefits. Still, certain general themes and
rough thresholds aid in understanding how to squeeze just a bit
more out of the underlying hardware. In this section, we sketch
fundamental concepts that are common to all modern computer hardware;
although the precise details will vary, the general ideas remain
essentially the same.

In its most basic form, a computer consists of central processing unit
(CPU) having internal registers that access main memory (MM).
Registers in the CPU (on the order of hundreds of bytes) are among the
fastest forms of memory, while main memory (typically many gigabytes) is
orders of magnitude slower. An almost universally observed phenomenon is
that of \emcppsgloss{locality of reference}, which suggests that data that
resides in close proximity (in the virtual address space) is more likely
to be accessed together in rapid succession than more distant data.

To exploit the phenomenon of \emcppsgloss{locality of reference}, computers
introduce the notion of a cache that, while much faster than main
memory, is also much smaller. Programs that attempt to amplify
\emcppsgloss{locality of reference} will, in turn, often be rewarded with
faster run times. The organization of a cache and, in fact, the number of
levels of cache (e.g., L1, L2, L3,$\ldots$) will vary, but the basic
design parameters are, again, more or less the same. A given level of
cache will have a certain total size in bytes (invariably an integral
power of two). The cache will be segmented into what are called
\emcppsgloss[cache line]{cache lines} whose size (a smaller power of two) divides that of
the cache itself. When the CPU accesses main memory, it first looks to
see if that memory is in the cache; if it is, the value is returned
quickly (known as a \emcppsgloss{cache hit}). Otherwise, the cache line(s)
containing that data is (are) fetched (from the next higher level of cache
or from main memory) and placed into the cache (known as a \emcppsgloss{cache
miss}), possibly ejecting other less recently used
ones.{\cprotect\footnote{Conceptually, the cache is often thought of as
being able to hold any arbitrary subset of the most recently accessed
cache lines. This kind of cache is known as \emcppsgloss{fully
associative}. Although it provides the best hit rate, a \emcppsgloss{fully
associative} cache requires the most power along with significant
additional chip area to perform the fully parallel lookup. \emcppsgloss[direct mapped]{Direct-mapped} cache associativity is at the
other extreme. In direct mapped, each memory location has exactly one location
available to it in the cache. If another memory location mapping to
that location is needed, the current cache line must be flushed from
the cache. Although this approach has the lowest hit rate, lookup
times, chip area, and power consumption are all minimized (optimally).
Between these two extremes is a continuum that is referred to as
\emcppsgloss{set associative}. A \emcppsgloss[set associative]{set associate} cache has more than
  one (typically 2, 4, or 8; see \cite{solihin15}, section~5.2.1, ``Placement Policy," pp. 136--141, and \cite{hruska20})
  location in which each memory location in main memory can reside.
  Note that, even with a relatively small $N$, as $N$ increases, an $N$-way
  \emcppsgloss{set associative} cache quickly approaches the hit rate of a fully
  associative cache at greatly reduced collateral cost; for most
  software-design purposes, any loss in hit rate due to set
  associativity of a cache can be safely ignored.}}

Data residing in distinct cache lines is physically independent and can
be written concurrently by multiple threads, possibly running on separate cores or even processors. Logically unrelated data
residing in the same cache line, however, is nonetheless physically
coupled; two threads that write to such logically unrelated data will find
themselves synchronized by the hardware. Such unexpected and typically
undesirable sharing of a cache line by unrelated data acted upon by two
concurrent threads is known as \emcppsgloss{false sharing}. One way of
avoiding \emcppsgloss{false sharing} is to align such data on a cache-line
boundary, thus rendering accidental collocation of such data on the same
cache line impossible. Another (more broad-based) design approach that
avoids lowering cache utilization is to ensure that data acted upon by a
given thread is kept physically separate --- e.g., through the use of
local (arena) memory allocators.{\cprotect\footnote{\cite{{lakos17}},
  \cite{{lakos19}}, \cite{{lakos22}}}}

Finally, even data that is not currently in cache but resides nearby in
MM can benefit from locality. The virtual address space, synonymous with
the size of a \lstinline!void*! (typically 64-bits on modern general-purpose hardware), has historically well exceeded the physical memory
available to the CPU. The operating system must therefore maintain a
mapping (in main memory) from what is resident in physical memory and
what resides in secondary storage (e.g., on disc). In addition,
essentially all modern hardware provides a
\emcppsgloss{TLB}{\cprotect\footnote{A translation-lookaside buffer (TLB) is
a kind of address-translation cache that is typically part of a chip's
memory management unit (MMU). A TLB holds a recently accessed subset
of the complete mapping (itself maintained in MM) from virtual memory
address to physical ones. A TLB is used to reduce access time when the
requisite pages are already resident in memory; its size (e.g., 4K) is
capped at the number of bytes of physical memory (e.g., 32Gb) divided
by the number of bytes in each physical page (e.g., 8Kb), but could be
smaller. Because it resides on chip, is typically an order of
magnitude faster (SRAM versus DRAM), and requires only a single lookup
(as opposed to two or more when going out to MM), there is an enormous
  premium on minimizing TLB misses.}} that caches the addresses of the
most recently accessed physical pages, providing yet another advantage
to having the \emcppsgloss{working set} (i.e., the current set of frequently
accessed pages) remain small and densely packed with relevant
data.{\cprotect\footnote{Note that memory for handle-body
types (e.g., \lstinline!std::vector! or \lstinline!std::deque!) and
especially node-based containers (e.g., \lstinline!std::map! and
\lstinline!std::unordered_map!), originally allocated within a single
page, can --- through deallocation and reallocation (or even move
operations) --- become scattered across multiple (perhaps many)
 pages, thus causing what was originally a relatively small \emcppsgloss{working set}
to no longer fit within physical memory. This phenomenon, known as
\emcppsgloss{diffusion} (which is a distinct concept from
\emcppsgloss{fragmentation}), is what typically leads to a substantial
runtime performance degradation (due to \emcppsgloss{thrashing}) in large,
long-running programs. Such \emcppsgloss{diffusion} can be mitigated by
judicious use of local arena memory allocators (and deliberate
avoidance of \emcppsgloss{move operations} across disparate localities of
  frequent memory usage).}} What's more, dense working sets, in addition
to facilitating hits for repeat access, increase the likelihood that
data that is coresident on a page (or cache line) will be needed soon
(i.e., in effect acting as a prefetch).{\cprotect\footnote{We sometimes
lightheartedly refer to the beneficial prefetch of unrelated data that
is accidentally needed subsequently (e.g., within a single thread) due
to high locality within a cache line (or a physical page) as
  \emcppsgloss{true sharing}.}} Table~\ref{table-alignas-appendix} provides a summary of typical physical parameters found in modern computers today.

%%%%%%TODO: TBD: @Lori: Format this as a figure with a caption. @jslakos: Double-check accuracy of values.

\begin{table}[h!]
\begin{center}
\begin{threeparttable}
\caption{Various sizes and access speeds of typical memory for modern \mbox{computers}}\label{table-alignas-appendix} \vspace{1.5ex}
{\small \begin{tabular}{c|c|c}\thickhline
\rowcolor[gray]{.9}    {\sffamily\bfseries Memory Type} & {\sffamily\bfseries Typical Memory Size (Bytes)} & {\sffamily\bfseries Typical Access Times}\\\hline
CPU Registers & 512 \ldots~2048 & $\sim$250ps\\ \hline
Cache Line  & 64 \ldots~256 & NA\\ \hline
L1 Cache & 16Kb \ldots~64Kb & $\sim$1ns\\ \hline
L2 Cache & 1Mb \ldots~2Mb & $\sim$10ns\\ \hline
L3 Cache & 8Mb \ldots~32Mb & $\sim$80ns--120ns\\ \hline
L4 Cache & 32Mb \ldots~128Mb & $\sim$100ns--200ns\\ \hline
Set Associativity  &  2 \ldots~64 & NA\\ \hline
TL & 4 words \ldots~65536 & 10ns \ldots~50ns\\ \hline
Physical Memory Page & 512 \ldots~8192 & 100ns \ldots~500ns\\ \hline
\rule{0pt}{3.5mm}Virtual Memory & $2^{32}$ bytes \ldots~$2^{64}$ bytes & $\sim$10$\mu$s--50$\mu$s\\ \hline
Solid-State Disc (SSD) & 256Gb \ldots~16Tb & $\sim$25$\mu$s--100$\mu$s\\ \hline
Mechanical Disc & Huge & $\sim$5ms--10ms\\ \hline
Clock Speed & NA & $\sim$4GHz \\ \thickhline
\end{tabular}
}
\end{threeparttable}
    \end{center}
\end{table}
\clearpage

